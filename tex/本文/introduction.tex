\section{はじめに}
「2048」はG.~Cirulliによって作られた確率的一人ゲームであり~\cite{2048}．
これまでにさまざまなコンピュータプレイヤが作られてきた．
現在最も成功しているアプローチは，強化学習によってチューニングしたNタプルネットワーク評価関数~\cite{SzJa14}とExpectimax探索~\cite{YWHC16}を組み合わせるものである．
その後，NタプルネットワークとExpectimax探索の組合せを基礎として，一般的もしくはゲームに特化した改良手法が多数提案されてきた~\cite{YWHC16,Mats17,Jask17,GuCW22}．
Gueiによって作られた最先端プレイヤ~\cite{GuCW22}では，大きさ6のタプル8個からなるネットワーク2つを切り替えて用いる評価関数，より幅広く学習するためのOptimistic Initialization，ゲーム特化型の改良手法であるTile downgrading，およびExpectimax探索を組み合わせることで，平均得点 625\,377 を達成した．

Nタプルネットワークやニューラルネットワークでは，一般に，ネットワーク内のパラメータ数が増えるほど性能が向上すると言われている~\cite{kaplan2020scaling}．一方で，パラメータ数が増えすぎると，学習に必要となるデータが莫大になるという問題に加えて，過学習（過適合）の問題も発生する．

2048のコンピュータプレイヤにおいては，これまでネットワークのパラメータ数を増やすことで性能向上が図られてきた．
2048にNタプルネットワークを用いる最初の研究である Szubert と Ja\'{s}kowski による研究~\cite{SzJa14}では，まず大きさ4のタプル17個からなるネットワーク（パラメータ数$1.11\times 10^6$）が用いられ，次に6タプル2個と4タプル2個からなるネットワーク（パラメータ数$3.37\times 10^7$）が用いられていた．
続く Wuらによる研究~\cite{W???14}では，ネットワークが大きさ6のタプル4つからなるもの（パラメータ数$6.71\times 10^7$）へ拡張された．
2018年時点での最先端プレイヤ~\cite{Jask18}では，6タプル5個にredundant encodingを組み合わせたネットワーク（パラメータ数 $8.42\times 10^7$）16個をゲーム進行に合わせて切り替える手法がとられている．論文投稿時点のGuei による最先端プレイヤ~\cite{GuCW22}では，Matsuzak~\cite{Mats16}が実験的に求めた6タプル8つの組合せ（パラメータ数 $1.34\times 10^8$）2つを切り替えて用いている．このGuei によるプレイヤの学習では，Optimistic Initialization を用いてより幅広く学習する工夫が取り入れられている．
一方，ニューラルネットワークによる評価関数を用いるプレイヤでは，Matsuzaki~\cite{Mats19}が，畳み込みネットワークのパラメータ数を $1.85\times 10^5$ から $2.90\times 10^6$ まで変化させたときに性能が向上することを報告している．

ここで生じる疑問は，2048のNタプル評価関数において，性能向上が見られる範囲でどこまでパラメータ数を増やしていけるのか，という点である．Oka と Matsuzaki~\cite{OkMa}，および，Matsuzaki~\cite{Mats16} は，大きさ6のタプルだけでなく，大きさ7のタプル複数個を系統的に組み合わせる手法を示し，同一条件での比較においては大きさ6のネットワークよりも大きさ7 のネットワークのほうが性能が高くなりうることを示した．
しかしながら，大きさ8のタプルからなるネットワークでは，単純に実装するとパラメータ数が $4.29\times 10^{12}$ と巨大になり，メモリサイズおよび学習コストの観点から，現時点では実現は困難である．


そこで本研究では，大きさが小さくパラメータ数を減らすことができ，また，すでに完全解析による真の正解が分かってるミニ2048を用いて，NタプルネットワークのタプルサイズとOptimistic Initialization（OI）の初期値がプレイヤの性能に与える影響について実験的に評価する．本研究の実施にあたって設定したリサーチクエスチョンは次の3つである．
\begin{itemize}
\item \textbf{RQ1} Nタプルネットワークにおけるタプルの大きさ，数，パラメータ数に対して，スコアにどのような影響があるか．
\item \textbf{RQ2} 幅広く強化学習を行う Optimistic Initialization の初期値を変えたときに，Nタプルネットワークの学習にどのような影響があるか．
\item \textbf{RQ3} Nタプルネットワーク評価関数とExpectimax探索とを組み合わせたとき，探索による性能向上はNタプルネットワークとその学習方法に依存するか．
\end{itemize}

本研究では，まず，タプルの大きさを1から9とし，そのそれぞれについて2種類のタプルの組合せによるNタプルネットワークを設計した．設計したNタプルネットワークに対し，Optimistic Initialization の初期値を変えた学習を行い，Expectimax 探索の深さを変えて各プレイヤの平均得点を調べた．これらの網羅的な実験の結果，以下に示す知見が得られた．
\begin{itemize}
\item RQ1に関して，パラメータ数の対数とスコアの間にはおよそ二次関数（放物線）の関係が見られる．とくに，タプルの大きさが 5 から 6 のときに性能のピークがある．
\item RQ2に関して，Optimistic Initializationの初期値が小さすぎる（$\mbox{\itshape OI} = 0$）場合には，低いスコアで学習が止まってしまう場合がある．逆に，初期値が大きすぎる（$\mbox{\itshape OI} = 5400$）場合には，パラメータ数が多くなると学習が停滞することが見られた．初期値が適切である（$\mbox{\itshape OI} = 1200$）場合，学習が安定して進むだけでなく，より多くのパラメータ数からなるネットワークでスコアが最大化する効果が見られた．
\item RQ3に関して，Expectimax探索によるスコアの向上は，Optimistic Initialization の初期値やパラメータ数には大きく影響されない結果となった．具体的には，探索深さ  1（Greedy）から6に増やすと，理想的な最高平均得点5469点までの距離がおよそ半分に減っていた．
\end{itemize}

以上の結果は，2048型ゲームにおけるNタプルネットワークの構成や初期化戦略とプレイヤの性能の関係を解明する重要な一歩である．{\color{red}この文はまとめに移してはどうか？}